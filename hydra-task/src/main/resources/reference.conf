include "hydra-sources.conf"
include "hydra-paths.conf"

hydra.task {
  # defaults for tests/config expansion/etc where it doesn't really matter
  jobdir = minion/job-id/task-id/live
  jobid  = job-id
  node   = 0
  nodes  = 1
  port   = 1337

  # override with environment variables if available
  jobdir = ${?HYDRA_JOBDIR}
  jobid  = ${?HYDRA_JOBID}
  node   = ${?HYDRA_NODE}
  nodes  = ${?HYDRA_NODES}
  port   = ${?HYDRA_PORT}

  # derived shortcuts
  job/task = ${hydra.task.jobid}/${hydra.task.node}
}

# for now, just make TaskRunConfig a codable field where it is needed.
# we can change these classes to only use the exact subfields they need later.
com.addthis.hydra.task {
  run.TaskRunConfig {
    node = ${hydra.task.node}
    nodeCount = ${hydra.task.nodes}
    jobId = ${hydra.task.jobid}
    dir = "."
  }
  hoover.Hoover.config: {}
  output.tree.TreeMapper.config: {}
  output.AbstractDataOutput.config: {}
  source.DataSourceStreamList.config: {}
  source.DataSourceHashed.config: {}
  source.AbstractStreamFileDataSource.config: {}
}

com.addthis.hydra.task.output {
  tree.TreeMapper {
    live = false
    liveHost = localhost
    livePort = -1
    livePort = ${?qmaster.mesh.port}

    directory = data
    advanced {}
  }

  GangliaOutput {
    name  = name
    value = value
    group = group
    units = units
    tMax  = 1 minute
    dMax  = 1 minute
  }
}

com.addthis.hydra.task.map.StreamMapper {
  threads: 2
  stats: true
  metricTick: 1 second
  enableJmx: true
  emitTaskState: true
  dateFormat: "yyMMdd-HHmmss"
  map {}

  threads: ${?task.threads}
  enableJmx: ${?split.minion.usejmx}
  emitTaskState: ${?task.mapper.emitState}
  dateFormat: ${?task.mapper.dateFormat}
}

plugins {
  values output {
    file: com.addthis.hydra.task.output.ValuesOutputFile
  }

  output-sink {
    _class: com.addthis.hydra.task.output.TaskDataOutput
    _array { _class: chain, _primary: outputs }
    chain: TaskDataOutputChain
    empty: EmptyDataOutput
    file: DataOutputFile
    filtered: FilteredDataOutput
    ganglia: GangliaOutput
    http: DataOutputHttp
    tree: tree.TreeMapper
  }

  output-factory {
    _class: com.addthis.hydra.task.output.OutputWrapperFactory
    _default: file
    file: DefaultOutputWrapperFactory
  }

  values stream formatter {
    kv: com.addthis.hydra.task.output.ValueStreamFormatKV
    tsv: com.addthis.hydra.task.output.ValueStreamFormatTSV
  }

  output stream formatter {
    _class: com.addthis.hydra.task.output.OutputStreamFormatter
    channel: OutputStreamChannel
    column: OutputStreamColumnized
    noop: OutputStreamNoop
    json: OutputStreamJson
  }

  task {
    _class: com.addthis.hydra.task.run.TaskRunnable
    _default: map
    hoover: hoover.Hoover
    map: map.StreamMapper
    pipeline: pipeline.PipelineTask
  }

  factory input stream {
    "file": "com.addthis.hydra.task.source.FactoryInputStream$FileInputStreamSource"
    "inject": "com.addthis.hydra.task.source.FactoryInputStream$InjectorStreamSource"
    "socket": "com.addthis.hydra.task.source.FactoryInputStream$SocketInputStreamSource"
  }

  stream builder {
    sortDeDupe: com.addthis.hydra.task.map.SortedDeDupBuilder
    rowSplitter: com.addthis.hydra.task.map.StreamRowSplitBuilder
    each: com.addthis.hydra.task.map.EachStreamBuilder
    closeableFilter: com.addthis.hydra.task.map.CloseableBundleFilterStreamBuilder
    join: com.addthis.hydra.task.map.StreamJoin
    chain: com.addthis.hydra.task.map.StreamChain
    mapSplitter: com.addthis.hydra.task.map.StreamMapSplitBuilder
    repeat: com.addthis.hydra.task.map.RepeatBuilder
  }

  # FieldFilter is a final class, but this lets use `_primary: filter` logic anyway
  map-def-fields {
    _class: com.addthis.hydra.task.map.FieldFilter
    _default: { _class: FieldFilter, _primary: filter }
  }
}
